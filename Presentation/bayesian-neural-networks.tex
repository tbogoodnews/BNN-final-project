\documentclass{beamer}
\usetheme{Madrid}

\usepackage{multicol}
\definecolor{ReedRed}{RGB}{167, 14, 22} %Reed Red (primary)
\usecolortheme[named=ReedRed]{structure}
\useoutertheme{miniframes}
\useinnertheme{circles}
\usepackage{soul}


\usepackage{listings}


\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{snakes}
\usetikzlibrary{positioning}
\usepackage{rotating}

\usepackage[citestyle=apa,backend=biber,citestyle=numeric]{biblatex}
\addbibresource{../refs.bib}

\title{Bayesian Neural Networks}
\author{
	Ava, Conor, Taylor
}
\logo{
	\includegraphics[width=1cm]{../Images/reed-logo.png}
}
\institute{Reed College}
\setbeamertemplate{navigation symbols}{} % Remove nav bar

\begin{document}
	\section{Intro}
	
\begin{frame}[plain]
    \maketitle
\end{frame}



\begin{frame}{A Brief History}
	\begin{tikzpicture}[scale=0.5,every node/.style={outer sep=5pt}]
		%Notation: {year, the title of the event}
		%NOTE! Everyting is zero-based
		\def\ourInfo{{
				{"1979"," The patent a 'Method of providing digital signatures' is filed by \\ Ralph C. Merkle  \cite{merkle-patent}."},
				{"1999","The  original patent expires."},
				{"2009","Bitcoin uses Merkle Trees for 'block header commitment.' \cite{friedenbach_alm_2017}"},			
				{"2023","Twenty students taking a cryptography class ."},
		}}
		\pgfmathsetmacro{\length}{3}% Zero based.
		
		% Loop through the array containing all events.
		\foreach \i in {0, ..., \length}{
			\pgfmathsetmacro{\year}{\ourInfo[\i][0]}% Get the left cell (year)
			\pgfmathsetmacro{\eventName}{\ourInfo[\i][1]}% Get the right cell (event name)
			\draw[thick,red] (0,-2*\i-2)--(0,-2*\i);% Draw vertical line
			\ifnum \i=0 % Should be in red text
			\draw(0,-2*\i-1) node[black, right, align = left]{\eventName};% Display the event name
			\draw(0,-2*\i-1) node[black, left] {\year};
			\else % Should be in black text
			\draw(0,-2*\i-1) node[right, black]{\eventName};% Display the event name
			\draw(0,-2*\i-1) node[left] {\year};% Display the year
			\fi
		}
		% Draw the bullet with the dash
		\foreach \i in {0, ..., \length}{
			\filldraw[draw = white, fill = red,thick] (0,-2*\i-1) circle (5pt);
			\draw[thick,red] (-12pt,-2*\i-1)--(0,-2*\i-1);
		}
	\end{tikzpicture}
\end{frame}

\begin{frame}{Applications}
	\begin{multicols}{2}
		\begin{figure}
			\includegraphics[width=.4\textwidth]{../Images/xkcd_simple_answers.png}
			\caption{XKCD: "\textit{Simple Answers}" \cite{xkcd-simple-answers}}
		\end{figure}
		
		\columnbreak
		
		\null \vfill
		
		What are....

		
		\vfill \null
	\end{multicols}
\end{frame}

\section{Neural Networks}

\begin{frame}{Neural Networks (NN)}
	% A convolutional neural network has the same structure as a regular neural network
	% Except we slide over the image and take k
	\begin{figure}
	\begin{tikzpicture}
		% Define node styles
		\tikzstyle{neuron} = [circle, draw, minimum size=1.5cm];
		\tikzstyle{weight} = [font=\scriptsize];
		
		% Input layer (2 neurons)
		\node[neuron] (input1) at (-2,1) {Input 1};
		\node[neuron] (input2) at (-2,-1) {Input 2};
		
		% Hidden layer (3 neurons)
		\node[neuron] (hidden1) at (2,2) {Hidden 1};
		\node[neuron] (hidden2) at (2,0) {Hidden 2};
		\node[neuron] (hidden3) at (2,-2) {Hidden 3};
		
		% Output layer (2 neurons for classification)
		\node[neuron] (output1) at (6,1) {Class 1};
		\node[neuron] (output2) at (6,-1) {Class 2};
		
		% Connections with weights
		\draw[->] (input1) -- node[weight, above] {$w_{1,1}$} (hidden1);
		\draw[->] (input2) -- node[weight, above] {$w_{2,1}$} (hidden1);
		\draw[->] (input1) -- node[weight, right] {$w_{1,2}$} (hidden2);
		\draw[->] (input2) -- node[weight, right] {$w_{2,2}$} (hidden2);
		\draw[->] (input1) -- node[weight, above] {$w_{1,3}$} (hidden3);
		\draw[->] (input2) -- node[weight, above] {$w_{2,3}$} (hidden3);
		\draw[->] (hidden1) -- node[weight, right] {$v_{1,1}$} (output1);
		\draw[->] (hidden2) -- node[weight, right] {$v_{2,1}$} (output1);
		\draw[->] (hidden3) -- node[weight, right] {$v_{3,1}$} (output1);
		\draw[->] (hidden1) -- node[weight, above] {$v_{12}$} (output2);
		\draw[->] (hidden2) -- node[weight, above] {$v_{2,2}$} (output2);
		\draw[->] (hidden3) -- node[weight, above] {$v_{3,2}$} (output2);
	\end{tikzpicture}
		\caption{Example neural network}
	\end{figure}
\end{frame}

\begin{frame}{Issues with Neural Networks}
	\begin{multicols}{2}
		\begin{figure}
			\includegraphics[width=.4\textwidth]{../Images/xkcd_machine_learning.png}
			\caption{XKCD: "\textit{Machine Learning}" \cite{xkcd-ml}}
		\end{figure}
		
		\columnbreak
		
		\null \vfill
		\begin{itemize}
			\item Stir data and pray
			\item 
		\end{itemize}
		\vfill \null
	\end{multicols}
\end{frame}

\begin{frame}{Convolutional Neural Networks (CNN)}
	% A convolutional neural network has the same structure as a regular neural network
	% Except we slide over the image and take k
	\begin{figure}
		\includegraphics[width=.9\textwidth]{../Images/big-pic-cnn.jpg}
		\caption{CNN pipeline \cite{eli5CNN}}
	\end{figure}
\end{frame}

\begin{frame}{Convolutional Neural Networks (CNN)}
	% A convolutional neural network has the same structure as a regular neural network
	% Except we slide over the image and take k
	\begin{figure}
\begin{tikzpicture}[draw=black!50, node distance=0.5cm]
	% Input matrix
	\draw[step=0.5cm,color=black!30] (0,0) grid (3,3);
	\foreach \x in {0,1,2}
	\foreach \y in {0,1,2}
	\node at (\x*0.5+0.25,\y*0.5+0.25) {$x_{\x,\y}$};
	
	% Convolutional kernel
	\draw[step=0.5cm,color=red,thick] (0,0) grid (2,2);
	\foreach \x in {0,1}
	\foreach \y in {0,1}
	\node[fill=red!30,minimum size=0.5cm] at (\x*0.5+0.25,\y*0.5+0.25) {};
	
	% Output feature map
	\begin{scope}[shift={(4,0)}]
		\draw[step=0.5cm,color=black!30] (0,0) grid (2,2);
		\foreach \x in {0,1}
		\foreach \y in {0,1}
		\node[fill=blue!30,minimum size=0.5cm] at (\x*0.5+0.25,\y*0.5+0.25) {};
	\end{scope}
	
	% Sliding operation
	\draw[->,thick] (2,1) -- (3.5,1) node[midway,above] {Sliding};
	
	% Annotations
	\node[below=of current bounding box.south] {Input Matrix};
	\node[below=of current bounding box.south,shift={(4,0)}] {Output Feature Map};
	\node at (0,-1) {Convolutional Kernel};
\end{tikzpicture}
	\end{figure}
\end{frame}

\begin{frame}{Why we use CNNs}
	\begin{multicols}{2}
		\begin{figure}
			\includegraphics[width=.45\textwidth]{../Images/xkcd_self_driving.png}
			\caption{XKCD: "\textit{Self Driving}" \cite{xkcd-self-driving}}
		\end{figure}
		
		\columnbreak
		
		\null \vfill
		\begin{itemize}
			\item They are more efficient for image based tasks
			\item Channels...
		\end{itemize}
		\vfill \null
	\end{multicols}
\end{frame}

\section{Bayesian Neural Networks}

\begin{frame}{Bayesian Neural Network}
	% The relationship between BNN and CNNs is the same as NNs and CNNs
	\begin{figure}
		\includegraphics[width=.55\textwidth]{../Images/example_bnn.png}
		\caption{Example BNN  \cite{FleszarBNN}}
	\end{figure}
\end{frame}

\begin{frame}{BNN Neuron}
	% The relationship between BNN and CNNs is the same as NNs and CNNs
	\begin{figure}
		\includegraphics[width=.55\textwidth]{../Images/BNN-neuron.png}
		\caption{Example BNN Neuron \cite{hase2019machine}}
	\end{figure}
\end{frame}

\begin{frame}{Why we use BNN}
	\begin{multicols}{2}
		\begin{figure}
			\includegraphics[width=.45\textwidth]{../Images/xkcd_error_bars.png}
			\caption{XKCD: "\textit{Error Bars}" \cite{xkcd-self-driving}}
		\end{figure}
		
		\columnbreak
		
		\null \vfill
		\begin{itemize}
			\item We can put uncertainty on our weights
			\item ....
		\end{itemize}
		\vfill \null
	\end{multicols}
\end{frame}

\begin{frame}{Difference between BNNs and BCNNs}
	% The relationship between BNN and CNNs is the same as NNs and CNNs
	\begin{figure}
		\includegraphics[width=.75\textwidth]{../Images/the_general_problem.png}
		\caption{ XKCD: "\textit{The General Problem}" \cite{xkcd-general-problem}}
	\end{figure}
		The relationship between BNNs and BCNNs is the same as NNs and CNNs.
\end{frame}


\section{Simulation}

\begin{frame}{CIFAR-10}
	% A convolutional neural network has the same structure as a regular neural network
	% Except we slide over the image and take k
	\begin{figure}
		\includegraphics[width=.65\textwidth]{../Images/cifar-10.png}
		\caption{Example CIFAR-10 images \cite{cifar10}}
	\end{figure}
\end{frame}

\begin{frame}{Hyperparameters}
	% Replace cell text later
	\centering
	\begin{tabular}{|c||p{3cm}|p{3cm}|} % Adjust p{width} as needed
		\hline
		\textbf{Hyperparameter} & \textbf{CNN} & \textbf{BCNN} \\ [0.5ex] 
		\hline\hline
		Epochs & 50 & 50\\
		\hline
		Learning Rate & 0.0004  & 0.0004  \\
		\hline
		Regularization Rate& 0.0001 & 0.0001 \\
		\hline
		Optimizer & Adamw  & Adamw  \\
		\hline
	\end{tabular}
\end{frame}

\begin{frame}{Results}
	% Image Later
	\centering
	\begin{tabular}{|c||p{3cm}|p{3cm}|} % Adjust p{width} as needed
		\hline
		\textbf{Metrix} & \textbf{CNN} & \textbf{BCNN} \\ [0.5ex] 
		\hline\hline
		Train Accuracy & 81.609\% & 70.664\%\\
		\hline
		Validation Accuracy & 64.499\%  & 61.399\%  \\
		\hline
		Optimizer & Adamw  & Adamw  \\
		\hline
	\end{tabular}
\end{frame}

\begin{frame}{Confusion Matrix (CNN)}
	% Image Later
	\begin{figure}
		\includegraphics[width=.95\textwidth]{../Images/CNN_confusion_matrix.png}
	\end{figure}
\end{frame}

\begin{frame}{Confusion Matrix (BCNN)}
	% Image Later
	\begin{figure}
		\includegraphics[width=.95\textwidth]{../Images/BNN_confusion_matrix.png}
	\end{figure}
\end{frame}

\begin{frame}{Live Demo}
	\begin{figure}
		\includegraphics[width=.35\textwidth]{../Images/xkcd_laws_of_physics.png}
		\caption{XKCD: "\textit{Laws of Physics}" \cite{xkcd-laws-of-physics}}
	\end{figure}
\end{frame}

\section{Closing}

\begin{frame}{Questions}
	\begin{figure}
		\includegraphics[width=.4\textwidth]{../Images/xkcd_simple_answers.png}
		\caption{XKCD: "\textit{Simple Answers}" \cite{xkcd-simple-answers}}
	\end{figure}
\end{frame}

\begin{frame}[allowframebreaks]{References}
\printbibliography
\end{frame}

\end{document}


